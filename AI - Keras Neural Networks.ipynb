{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI - Keras Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La spécificité de keras est quelle utilise TensorFlow et Theano comme \"engine\". Cette librairie permet de se concentrer sur l'aspect design et training et les specificités liées au tensor sont laissé à tensorflow et theano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.datasets import imdb, reuters\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Sommaire\n",
    "\n",
    "[I. Designing a neural network](#Partie1)\n",
    "\n",
    "[II. Training a binary and multiclass classifier](#Partie2)\n",
    "- [II.1. Binary](#Partie2.1) \n",
    "- [II.2. Multiclass](#Partie2.2) \n",
    "\n",
    "[III. Training a regressor](#Partie3)\n",
    "\n",
    "[IV. Visualizing training and making predictions](#Partie4)\n",
    "- [IV.1. Visualizing training](#Partie4.1) \n",
    "- [IV.2. Making predictions](#Partie4.2) \n",
    "\n",
    "[V. Reduce overfitting](#Partie5)\n",
    "- [V.1. With weight regularization](#Partie5.1) \n",
    "- [V.2. With early stopping](#Partie5.2)\n",
    "- [V.3. With dropout](#Partie5.3) \n",
    "\n",
    "[VI. Saving model training progress](#Partie6)\n",
    "\n",
    "[VII. k-fold cross-validation and tunning a neural network](#Partie7)\n",
    "- [VII.1. K-fold cross validation](#Partie7.1) \n",
    "- [VII.2. Tuning neural networks](#Partie7.2)\n",
    "\n",
    "[VIII. Visualizing neural networks](#Partie8)\n",
    "\n",
    "[IX. Classifying images](#Partie9)\n",
    "- [IX.1. Image classification](#Partie9.1) \n",
    "- [IX.2. Improving performance with image augmentation](#Partie9.2)\n",
    "\n",
    "[X. Classifying text](#Partie10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Designing a neural network<a class=\"anchor\" id=\"Partie1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord les données sont preprocessées selon leur type (si numérique alors on utilise standardscaler)\n",
    "\n",
    "Les reseaux de neurones consistent en des couches d'unité (neurone). Pour construire ici un reseau feed forward on doit faire plusieurs choix pour l'architecture et le processus d'entrainement. Il faut tout d'abord se rappeler que chaque unit (ie neurone) recoit :\n",
    "- un certain nombe d'inputs\n",
    "- toutes les inputs sont pondérés par un paramètre\n",
    "- on fait la combinaison linéaire de toutes les inputs pondérés et d'un biais (1 en général)\n",
    "- on y applique ensuite une fonction d'activation\n",
    "- on envoie l'output a la couche suivante\n",
    "\n",
    "1/ De manière générale: plus il y a de neurones sur une couche plus le reseau sera capable d'apprendre des pattern complexes mais plus le reseau est susceptible de surappendre. On doit d'abord chosir la fonction d'activation (relu est un bon choix si la somme pondérée est inférieur à 0 alors la fonction renvoie 0 sinon elle renvoie la somme)\n",
    "\n",
    "2/ On doit ensuite définir le nombre de couche cachée à ajouter à l'architecture. Plus il y a de couche plus le reseau peut appendre des relations complexes mais avec un coût sur la complexité.\n",
    " \n",
    "3/On doit ensuite définir la couche d'activation pour la dernière couche. Cela depend du but du reseau:\n",
    "- pour une classification binaire on utilisera sigmoide\n",
    "- pour une classifcation multiclass on utilisera softmax\n",
    "- pour une regression on utilisera pas d'activation (ie linéaire)\n",
    "\n",
    "4/ Dans un 4eme temps on définit la loss function (qui mesure à quel point les valeurs prédites sont poches des vrais valeurs)\n",
    "- binary classification: binary cross entropy\n",
    "- multiclass classification: categorical cross entropy\n",
    "- regression: mse\n",
    "\n",
    "5/ On définit ensuite \"l'optimizer\" qui est note stratégie pour trouver les meilleurs paramètres pou poduire une loss minimale. les choix communs sont: stochastic gradient descent, with momentum, rms propagation, adaptative moment...\n",
    "\n",
    "6/ On selectionne les metriques de performance de notre algorithme.\n",
    "\n",
    "Keras permet de construire un reseau avec sequential qui va juxtaposer chaque couche. Dans notre reseau on a crée un reseau à 2 couches (on ne compte pas la couche d'entrée car elle n'a pas de poid). Les couches sont \"dense\" (qui correspond à des couches fully connected ie tous les neurones de la couche précédente sont connectés au neurones de la couche suivante). Units=16 signifie qu'il y a 16 neurones sur la couche. Dans Keras la première couche cachée doti comporter l'argument \"input_shape\" qui est la dimension des features (ie leur nombre). (10,) signifie que chaque observation a 10 features. ici on a designé un reseau pour une classification binaire donc il y a une seule sortie avec activation sigmoide qui sera entre 0 et 1 qui correspond à la probabilité d'obtenir la classe 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "network=models.Sequential() #start neural network\n",
    "\n",
    "network.add(layers.Dense(units=16,activation=\"relu\",input_shape=(10,))) #ajout d'une fully connected layer avec Relu\n",
    "network.add(layers.Dense(units=16,activation=\"relu\")) #ajout d'une fully connected layer avec Relu\n",
    "network.add(layers.Dense(units=1,activation=\"sigmoid\")) #ajout d'une fully connected layer avec sigmoide\n",
    "\n",
    "network.compile(loss=\"binary_crossentropy\", # loss de cross entropy pour pb de classification\n",
    "                optimizer=\"rmsprop\", # propagation avec root mean square \n",
    "                metrics=[\"accuracy\"]) #accuracy comme metrique de performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Training a binary and multiclass classifier<a class=\"anchor\" id=\"Partie2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1. Binary<a class=\"anchor\" id=\"Partie2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet entrainement d'un modele de classification binaire on utilise les données: de movie review (text) qui sont catégorisées en bonne (1) ou mauvaise (0). On convertit les reviews en 5000 features binaire qui indique ou non la présence des 1000 mots les plus fréquents (en one-hot encoder: si mot existe 1 sinon 0). Ces one hot vecteurs correspondent au set de train et test avec leur label correspondant.\n",
    "\n",
    "On utilise la fonction fit de Keras pour entrainer le modèle:\n",
    "- 2 premiers paramètres: features et target vecteurs du set de train\n",
    "- paramètre epoch: nombre d'itération de train sur tout le set de train (ie tous les batchs)\n",
    "- verbose 0,1,2 : donne des informations plus ou moins détaillé sur les epochs\n",
    "- batch_size: taille des batchs pendant les epoch\n",
    "- test data\n",
    "\n",
    "La méthode fit de Keras renvoie un object qui contient les valeurs de loss et les metriques de performance demandées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "250/250 [==============================] - 2s 4ms/step - loss: 0.4099 - accuracy: 0.8161 - val_loss: 0.3426 - val_accuracy: 0.8536\n",
      "Epoch 2/3\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8640 - val_loss: 0.3304 - val_accuracy: 0.8592\n",
      "Epoch 3/3\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8698 - val_loss: 0.3278 - val_accuracy: 0.8592\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) #on confidure la random seed\n",
    "number_of_features=1000 #nombre de features dans le set\n",
    "\n",
    "#on utilise le set movie review pour créer le set de train et test\n",
    "(data_train,target_train),(data_test,target_test)=imdb.load_data(num_words=number_of_features) \n",
    "\n",
    "#On convertit les data movie review en one-hot feature matrice encodée\n",
    "# dans les observation on ne garde que les 1000 mots les plus féquents des data set\n",
    "# en encodant les obersavtion en one hot vecteur de longeur 1000\n",
    "tokenizer=Tokenizer(num_words=number_of_features) \n",
    "features_train=tokenizer.sequences_to_matrix(data_train,mode=\"binary\")\n",
    "features_test=tokenizer.sequences_to_matrix(data_test,mode=\"binary\")\n",
    "\n",
    "network=models.Sequential() #start neural network\n",
    "\n",
    "network.add(layers.Dense(units=16,activation=\"relu\",input_shape=(number_of_features,))) \n",
    "network.add(layers.Dense(units=16,activation=\"relu\"))\n",
    "network.add(layers.Dense(units=1,activation=\"sigmoid\")) \n",
    "\n",
    "network.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=\"rmsprop\", \n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# train neural network\n",
    "\n",
    "history=network.fit(features_train, #set de training\n",
    "                    target_train, #label de training\n",
    "                    epochs=3, #nombre d'epoch\n",
    "                    verbose=1, #print la description a chaque epoch\n",
    "                    batch_size=100, #nombre d'observation par batch\n",
    "                    validation_data=(features_test,target_test)) #test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Multiclass<a class=\"anchor\" id=\"Partie2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La différence entre le classifier ci-dessus et dessous est la catégorisation en 46 classe plutôt que une classe 0 et une classe 1 il doit donc y avoir 46 noeuds sur la dernière couche par rapport à un noeud sur la première. Le vecteur de target doit donc également être encodé en one-hot, c'est à dire chaque ligne de ces matrices contient 46 élements avec des 0 partout sauf au numéro de la classe correspondante.\n",
    "Un élément important à prendre en compte est l'utilisation de la fonction d'activation softmax sur la dernière couche qui va permettre d'avoir une somme des issues égale à 1 (correspondant donc au probabilité d'occurence de chaque classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "90/90 [==============================] - 2s 14ms/step - loss: 1.5281 - accuracy: 0.6729 - val_loss: 1.1204 - val_accuracy: 0.7502\n",
      "Epoch 2/3\n",
      "90/90 [==============================] - 1s 13ms/step - loss: 0.7950 - accuracy: 0.8250 - val_loss: 0.9481 - val_accuracy: 0.7801\n",
      "Epoch 3/3\n",
      "90/90 [==============================] - 1s 13ms/step - loss: 0.5079 - accuracy: 0.8884 - val_loss: 0.8704 - val_accuracy: 0.8045\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) #on confidure la random seed\n",
    "number_of_features=5000 #nombre de features dans le set\n",
    "\n",
    "#on utilise le set reuters pour créer le set de train et test\n",
    "data=reuters.load_data(num_words=number_of_features) \n",
    "(data_train,target_train),(data_test,target_test)=data\n",
    "\n",
    "# On convertit les data movie review en one-hot feature matrice encodée\n",
    "# dans les observation on ne garde que les 5000 mots les plus féquents des data set\n",
    "# en encodant les obersavtion en one hot vecteur de longeur 1000\n",
    "tokenizer=Tokenizer(num_words=number_of_features) \n",
    "features_train=tokenizer.sequences_to_matrix(data_train,mode=\"binary\")\n",
    "features_test=tokenizer.sequences_to_matrix(data_test,mode=\"binary\")\n",
    "\n",
    "# on one-hot encode le vecteur de target\n",
    "target_train=to_categorical(target_train)\n",
    "target_test=to_categorical(target_test)\n",
    "\n",
    "\n",
    "network=models.Sequential() #start neural network\n",
    "\n",
    "network.add(layers.Dense(units=100,activation=\"relu\",input_shape=(number_of_features,))) \n",
    "network.add(layers.Dense(units=100,activation=\"relu\"))\n",
    "network.add(layers.Dense(units=46,activation=\"softmax\")) #units = nombre de classe dans le set\n",
    "\n",
    "network.compile(loss=\"categorical_crossentropy\", \n",
    "                optimizer=\"rmsprop\", \n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# train neural network\n",
    "\n",
    "history=network.fit(features_train, #set de training\n",
    "                    target_train, #label de training\n",
    "                    epochs=3, #nombre d'epoch\n",
    "                    verbose=1, #print la description a chaque epoch\n",
    "                    batch_size=100, #nombre d'observation par batch\n",
    "                    validation_data=(features_test,target_test)) #test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Training a regressor<a class=\"anchor\" id=\"Partie3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les cas précédents nous appliquions des fonctions activation sur la dernière couche. Dans le cas d'une regression on utilise une activation \"linéaire\" c'est à dire on utilise pas de fonction d'activation on renvoie directement le résultat de la combinaison linéaire de la dernière couche de neurones. On utilise ici une loss approriée comme la mse ou la mae selon la distribution des valeurs et notamment des anomalies pour leur donner plus ou moins de poid.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 1s 5ms/step - loss: 17370.6191 - mse: 17370.6191 - val_loss: 17791.0059 - val_mse: 17791.0059\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 16634.7871 - mse: 16634.7871 - val_loss: 16710.4590 - val_mse: 16710.4590\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 15253.0352 - mse: 15253.0352 - val_loss: 14869.9717 - val_mse: 14869.9717\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 13108.6738 - mse: 13108.6738 - val_loss: 12225.5879 - val_mse: 12225.5879\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 10227.8320 - mse: 10227.8320 - val_loss: 8932.6895 - val_mse: 8932.6895\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 6846.4551 - mse: 6846.4551 - val_loss: 5367.4854 - val_mse: 5367.4854\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 3637.7449 - mse: 3637.7449 - val_loss: 2392.7490 - val_mse: 2392.7490\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 1370.6443 - mse: 1370.6443 - val_loss: 737.3975 - val_mse: 737.3975\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 479.2162 - mse: 479.2162 - val_loss: 348.8980 - val_mse: 348.8980\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 287.8663 - mse: 287.8663 - val_loss: 233.5701 - val_mse: 233.5701\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 0s 4ms/step - loss: 210.0968 - mse: 210.0968 - val_loss: 185.9083 - val_mse: 185.9083\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 173.3139 - mse: 173.3139 - val_loss: 152.1848 - val_mse: 152.1848\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 141.9967 - mse: 141.9967 - val_loss: 125.4118 - val_mse: 125.4118\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 112.3732 - mse: 112.3732 - val_loss: 95.1149 - val_mse: 95.1149\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 82.6495 - mse: 82.6495 - val_loss: 66.4686 - val_mse: 66.4686\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 55.6579 - mse: 55.6579 - val_loss: 41.4814 - val_mse: 41.4814\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 32.5915 - mse: 32.5915 - val_loss: 21.4092 - val_mse: 21.4092\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 15.7527 - mse: 15.7527 - val_loss: 9.0149 - val_mse: 9.0149\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 5.8663 - mse: 5.8663 - val_loss: 2.9714 - val_mse: 2.9714\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 2.3330 - mse: 2.3330 - val_loss: 1.7560 - val_mse: 1.7560\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.6063 - mse: 1.6063 - val_loss: 1.1769 - val_mse: 1.1769\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.1676 - mse: 1.1676 - val_loss: 1.1702 - val_mse: 1.1702\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 1.0273 - mse: 1.0273 - val_loss: 0.7960 - val_mse: 0.7960\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.9237 - mse: 0.9237 - val_loss: 1.1083 - val_mse: 1.1083\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7970 - mse: 0.7970 - val_loss: 0.7552 - val_mse: 0.7552\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7547 - mse: 0.7547 - val_loss: 1.1080 - val_mse: 1.1080\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.7101 - mse: 0.7101 - val_loss: 0.4758 - val_mse: 0.4758\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6767 - mse: 0.6767 - val_loss: 0.4958 - val_mse: 0.4958\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6183 - mse: 0.6183 - val_loss: 0.7565 - val_mse: 0.7565\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.6110 - mse: 0.6110 - val_loss: 0.8275 - val_mse: 0.8275\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5955 - mse: 0.5955 - val_loss: 0.5795 - val_mse: 0.5795\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5508 - mse: 0.5508 - val_loss: 1.8938 - val_mse: 1.8938\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5293 - mse: 0.5293 - val_loss: 0.6668 - val_mse: 0.6668\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.5252 - mse: 0.5252 - val_loss: 0.5537 - val_mse: 0.5537\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5076 - mse: 0.5076 - val_loss: 0.6441 - val_mse: 0.6441\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.5079 - mse: 0.5079 - val_loss: 0.4433 - val_mse: 0.4433\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4917 - mse: 0.4917 - val_loss: 0.3997 - val_mse: 0.3997\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4752 - mse: 0.4752 - val_loss: 0.3171 - val_mse: 0.3171\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4802 - mse: 0.4802 - val_loss: 0.2423 - val_mse: 0.2423\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4481 - mse: 0.4481 - val_loss: 0.4551 - val_mse: 0.4551\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4591 - mse: 0.4591 - val_loss: 0.2264 - val_mse: 0.2264\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4186 - mse: 0.4186 - val_loss: 0.2716 - val_mse: 0.2716\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.4189 - mse: 0.4189 - val_loss: 0.2253 - val_mse: 0.2253\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.4262 - mse: 0.4262 - val_loss: 0.2241 - val_mse: 0.2241\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.4210 - mse: 0.4210 - val_loss: 0.6993 - val_mse: 0.6993\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 0s 3ms/step - loss: 0.4454 - mse: 0.4454 - val_loss: 0.2093 - val_mse: 0.2093\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3783 - mse: 0.3783 - val_loss: 0.6250 - val_mse: 0.6250\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3977 - mse: 0.3977 - val_loss: 0.2544 - val_mse: 0.2544\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3931 - mse: 0.3931 - val_loss: 0.3038 - val_mse: 0.3038\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 0s 2ms/step - loss: 0.3594 - mse: 0.3594 - val_loss: 0.3666 - val_mse: 0.3666\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) #on confidure la random seed\n",
    "\n",
    "#on génere les matrices de features et de target\n",
    "features,target=make_regression(n_samples=10000,\n",
    "                                n_features=3,\n",
    "                                n_informative=3,\n",
    "                                n_targets=1,\n",
    "                                noise=0,\n",
    "                                random_state=0)\n",
    "\n",
    "# On divise notre matrice et nos targets en train et test\n",
    "features_train, features_test, target_train,target_test=train_test_split(features, target, test_size=0.33, random_state=0)\n",
    "\n",
    "network=models.Sequential() #start neural network\n",
    "\n",
    "network.add(layers.Dense(units=32,activation=\"relu\",input_shape=(features_train.shape[1],))) \n",
    "network.add(layers.Dense(units=32,activation=\"relu\"))\n",
    "network.add(layers.Dense(units=1))\n",
    "\n",
    "network.compile(loss=\"mse\", \n",
    "                optimizer=\"RMSprop\", \n",
    "                metrics=[\"mse\"])\n",
    "\n",
    "# train neural network\n",
    "\n",
    "history=network.fit(features_train, #set de training\n",
    "                    target_train, #label de training\n",
    "                    epochs=50, #nombre d'epoch\n",
    "                    verbose=1, #print la description a chaque epoch\n",
    "                    batch_size=100, #nombre d'observation par batch\n",
    "                    validation_data=(features_test,target_test)) #test data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Visualizing training and making predictions<a class=\"anchor\" id=\"Partie4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.4308 - accuracy: 0.8066 - val_loss: 0.3411 - val_accuracy: 0.8560\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3249 - accuracy: 0.8641 - val_loss: 0.3482 - val_accuracy: 0.8515\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8705 - val_loss: 0.3266 - val_accuracy: 0.8611\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.3062 - accuracy: 0.8718 - val_loss: 0.3364 - val_accuracy: 0.8562\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2961 - accuracy: 0.8772 - val_loss: 0.3311 - val_accuracy: 0.8590\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2864 - accuracy: 0.8807 - val_loss: 0.3336 - val_accuracy: 0.8597\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2753 - accuracy: 0.8866 - val_loss: 0.3386 - val_accuracy: 0.8565\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2650 - accuracy: 0.8907 - val_loss: 0.3434 - val_accuracy: 0.8564\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2529 - accuracy: 0.8976 - val_loss: 0.3417 - val_accuracy: 0.8560\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2439 - accuracy: 0.9015 - val_loss: 0.3630 - val_accuracy: 0.8452\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2328 - accuracy: 0.9074 - val_loss: 0.3628 - val_accuracy: 0.8493\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2231 - accuracy: 0.9115 - val_loss: 0.3702 - val_accuracy: 0.8495\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2143 - accuracy: 0.9166 - val_loss: 0.4071 - val_accuracy: 0.8455\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.2043 - accuracy: 0.9209 - val_loss: 0.4041 - val_accuracy: 0.8446\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1948 - accuracy: 0.9257 - val_loss: 0.4198 - val_accuracy: 0.8430\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1845 - accuracy: 0.9310 - val_loss: 0.4350 - val_accuracy: 0.8415\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1749 - accuracy: 0.9356 - val_loss: 0.4495 - val_accuracy: 0.8372\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1629 - accuracy: 0.9403 - val_loss: 0.4850 - val_accuracy: 0.8385\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1523 - accuracy: 0.9467 - val_loss: 0.5006 - val_accuracy: 0.8388\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1426 - accuracy: 0.9492 - val_loss: 0.5385 - val_accuracy: 0.8336\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1321 - accuracy: 0.9540 - val_loss: 0.5543 - val_accuracy: 0.8312\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9576 - val_loss: 0.5844 - val_accuracy: 0.8300\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1152 - accuracy: 0.9612 - val_loss: 0.6267 - val_accuracy: 0.8321\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.1055 - accuracy: 0.9647 - val_loss: 0.6775 - val_accuracy: 0.8308\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0974 - accuracy: 0.9687 - val_loss: 0.7270 - val_accuracy: 0.8291\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0899 - accuracy: 0.9714 - val_loss: 0.7666 - val_accuracy: 0.8298\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.9740 - val_loss: 0.8124 - val_accuracy: 0.8263\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9769 - val_loss: 0.8428 - val_accuracy: 0.8262\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9796 - val_loss: 0.8726 - val_accuracy: 0.8227\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 0.0631 - accuracy: 0.9822 - val_loss: 0.9145 - val_accuracy: 0.8228\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0) #on confidure la random seed\n",
    "number_of_features=1000 #nombre de features dans le set\n",
    "\n",
    "#on utilise le set movie review pour créer le set de train et test\n",
    "(data_train,target_train),(data_test,target_test)=imdb.load_data(num_words=number_of_features) \n",
    "\n",
    "#On convertit les data movie review en one-hot feature matrice encodée\n",
    "# dans les observation on ne garde que les 1000 mots les plus féquents des data set\n",
    "# en encodant les obersavtion en one hot vecteur de longeur 1000\n",
    "tokenizer=Tokenizer(num_words=number_of_features) \n",
    "features_train=tokenizer.sequences_to_matrix(data_train,mode=\"binary\")\n",
    "features_test=tokenizer.sequences_to_matrix(data_test,mode=\"binary\")\n",
    "\n",
    "network=models.Sequential() #start neural network\n",
    "\n",
    "network.add(layers.Dense(units=16,activation=\"relu\",input_shape=(number_of_features,))) \n",
    "network.add(layers.Dense(units=16,activation=\"relu\"))\n",
    "network.add(layers.Dense(units=1,activation=\"sigmoid\")) \n",
    "\n",
    "network.compile(loss=\"binary_crossentropy\", \n",
    "                optimizer=\"rmsprop\", \n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "# train neural network\n",
    "\n",
    "history=network.fit(features_train, #set de training\n",
    "                    target_train, #label de training\n",
    "                    epochs=30, #nombre d'epoch\n",
    "                    verbose=1, #print la description a chaque epoch\n",
    "                    batch_size=100, #nombre d'observation par batch\n",
    "                    validation_data=(features_test,target_test)) #test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.1. Visualizing training<a class=\"anchor\" id=\"Partie4.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendant l'entrainement du resueau de neurones les 2 erreurs de test et de train vont diminuer. Mais à un certain point le réseau va sur-apprendre le set de train et se se \"rémorer\" celui-ci. C'est alors que l'on voit une divergence de croissance entre l'erreur de training et celle de test.  Il faut donc arreter l'entrainement avant cet instant là pour avoir une erreur de validation minmale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# on recupère la loss de training et de validation et le nombre d'epoch\n",
    "training_loss=history.history[\"loss\"]\n",
    "test_loss=history.history[\"val_loss\"]\n",
    "epoch_count=range(1,len(training_loss)+1)\n",
    "\n",
    "# visualisation de la loss\n",
    "plt.plot(epoch_count[:15],training_loss[:15],\"r--\")\n",
    "plt.plot(epoch_count[:15],test_loss[:15],\"b-\")\n",
    "plt.legend([\"training\",\"test\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_acc=history.history[\"accuracy\"]\n",
    "test_acc=history.history[\"val_accuracy\"]\n",
    "\n",
    "# visualisation de l'accuracy\n",
    "plt.plot(epoch_count[:15],training_acc[:15],\"r--\")\n",
    "plt.plot(epoch_count[:15],test_acc[:15],\"b-\")\n",
    "plt.legend([\"training\",\"test\"])\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"mse\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV.2. Making predictions<a class=\"anchor\" id=\"Partie4.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le réseau entrainé on utilise la fonction predict pour prédire de nouvelle valeur avec le reseau. si le reseau prédit l'issu d'une classification binaire (notre cas) le résultat est la probabilité d'obtenir 1. Si c'est une multiclassification on a alors la probabilité de toutes les classes et on peut obtenir la classe avec la probabilité maximum en utilisant la fonction argmax. Enfin si c'est une régression on va avoir la valeur réelle prédite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999017], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_target=network.predict(features_test)\n",
    "predicted_target[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Reduce overfitting<a class=\"anchor\" id=\"Partie5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.1. With weight regularization<a class=\"anchor\" id=\"Partie5.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.2. With early stopping<a class=\"anchor\" id=\"Partie5.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V.3. With dropout<a class=\"anchor\" id=\"Partie5.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Saving model training progress<a class=\"anchor\" id=\"Partie6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. k-fold cross-validation and tunning a neural network<a class=\"anchor\" id=\"Partie7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII.1. K-fold cross validation<a class=\"anchor\" id=\"Partie7.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII.2. Tuning neural networks<a class=\"anchor\" id=\"Partie7.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Visualizing neural networks<a class=\"anchor\" id=\"Partie8\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Classifying images<a class=\"anchor\" id=\"Partie9\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IX.1. Image classification<a class=\"anchor\" id=\"Partie9.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IX.2. Improving performance with image augmentation<a class=\"anchor\" id=\"Partie9.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Classifying text<a class=\"anchor\" id=\"Partie10\"></a>"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "facb5e61a4394193cb0f4fe6a1e15649a9df4920ef6ba80a21095838ac15af6e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
